{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beneficial-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /anaconda3/envs/newenv\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    intel-openmp-2019.4        |              233         1.1 MB\n",
      "    llvm-openmp-10.0.0         |       h28b9765_0         270 KB\n",
      "    mkl-2019.4                 |              233       155.2 MB\n",
      "    mkl-service-2.3.0          |   py38h9ed2024_0          44 KB\n",
      "    mkl_fft-1.3.0              |   py38ha059aab_0         181 KB\n",
      "    mkl_random-1.1.1           |   py38h959d312_0         337 KB\n",
      "    numpy-1.19.2               |   py38h456fd55_0          20 KB\n",
      "    numpy-base-1.19.2          |   py38hcfb5961_0         5.1 MB\n",
      "    scikit-learn-0.24.1        |   py38hb2f4e1b_0         6.6 MB\n",
      "    scipy-1.6.1                |   py38h2515648_0        18.6 MB\n",
      "    threadpoolctl-2.1.0        |     pyh5ca1d4c_0          16 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       187.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  blas               pkgs/main/osx-64::blas-1.0-mkl\n",
      "  intel-openmp       pkgs/main/osx-64::intel-openmp-2019.4-233\n",
      "  joblib             pkgs/main/noarch::joblib-1.0.1-pyhd3eb1b0_0\n",
      "  libgfortran        pkgs/main/osx-64::libgfortran-3.0.1-h93005f0_2\n",
      "  llvm-openmp        pkgs/main/osx-64::llvm-openmp-10.0.0-h28b9765_0\n",
      "  mkl                pkgs/main/osx-64::mkl-2019.4-233\n",
      "  mkl-service        pkgs/main/osx-64::mkl-service-2.3.0-py38h9ed2024_0\n",
      "  mkl_fft            pkgs/main/osx-64::mkl_fft-1.3.0-py38ha059aab_0\n",
      "  mkl_random         pkgs/main/osx-64::mkl_random-1.1.1-py38h959d312_0\n",
      "  numpy              pkgs/main/osx-64::numpy-1.19.2-py38h456fd55_0\n",
      "  numpy-base         pkgs/main/osx-64::numpy-base-1.19.2-py38hcfb5961_0\n",
      "  scikit-learn       pkgs/main/osx-64::scikit-learn-0.24.1-py38hb2f4e1b_0\n",
      "  scipy              pkgs/main/osx-64::scipy-1.6.1-py38h2515648_0\n",
      "  threadpoolctl      pkgs/main/noarch::threadpoolctl-2.1.0-pyh5ca1d4c_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "numpy-base-1.19.2    | 5.1 MB    | ##################################### | 100% \n",
      "mkl_fft-1.3.0        | 181 KB    | ##################################### | 100% \n",
      "mkl-2019.4           | 155.2 MB  | ##################################### | 100% \n",
      "intel-openmp-2019.4  | 1.1 MB    | ##################################### | 100% \n",
      "scipy-1.6.1          | 18.6 MB   | ##################################### | 100% \n",
      "scikit-learn-0.24.1  | 6.6 MB    | ##################################### | 100% \n",
      "threadpoolctl-2.1.0  | 16 KB     | ##################################### | 100% \n",
      "numpy-1.19.2         | 20 KB     | ##################################### | 100% \n",
      "llvm-openmp-10.0.0   | 270 KB    | ##################################### | 100% \n",
      "mkl_random-1.1.1     | 337 KB    | ##################################### | 100% \n",
      "mkl-service-2.3.0    | 44 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "realistic-brush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.1-py3-none-any.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 110 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /anaconda3/envs/newenv/lib/python3.8/site-packages (from seaborn) (1.6.1)\n",
      "Collecting matplotlib>=2.2\n",
      "  Downloading matplotlib-3.3.4-cp38-cp38-macosx_10_9_x86_64.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 583 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=0.23\n",
      "  Downloading pandas-1.2.3-cp38-cp38-macosx_10_9_x86_64.whl (10.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.5 MB 519 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /anaconda3/envs/newenv/lib/python3.8/site-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /anaconda3/envs/newenv/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda3/envs/newenv/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp38-cp38-macosx_10_9_x86_64.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 282 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /anaconda3/envs/newenv/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.1.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /anaconda3/envs/newenv/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda3/envs/newenv/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Installing collected packages: kiwisolver, cycler, matplotlib, pandas, seaborn\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.4 pandas-1.2.3 seaborn-0.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "related-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports required packages\n",
    "\n",
    "import os\n",
    "import glob #to read batch of images at once\n",
    "import datetime\n",
    "\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compatible-boutique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with configuration/setup we will be using\n",
    "\n",
    "config={\n",
    "  \"model\"           : \"vgg16\",\n",
    "  \"weights\"         : \"imagenet\", \n",
    "  \"include_top\"     : False, #Don't include the last dense layer\n",
    "\n",
    "  \"train_path\"      : \"/Users/rishitdholakia/Desktop/Car Damage Detection project/data1a/training\",\n",
    "  \"test_path\"       : \"/Users/rishitdholakia/Desktop/Car Damage Detection project/data1a/validation\",\n",
    "  \"features_path\"   : \"/Users/rishitdholakia/Desktop/Car Damage Detection project/Car Damage check/features.h5\",\n",
    "  \"labels_path\"     : \"/Users/rishitdholakia/Desktop/Car Damage Detection project/Car Damage check/labels.h5\",\n",
    "  \"results\"         : \"/Users/rishitdholakia/Desktop/Car Damage Detection project/Car Damage check/results.txt\",\n",
    "  \"classifier_path\" : \"/Users/rishitdholakia/Desktop/Car Damage Detection project/Car Damage check/classifier.pickle\",\n",
    "  \"model_path\"      : \"/Users/rishitdholakia/Desktop/Car Damage Detection project/Car Damage check/model\",\n",
    "\n",
    "  \"test_size\"       : 0.20,\n",
    "  \"seed\"            : 9,\n",
    "  \"num_classes\"     : 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compliant-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning) #Suppress Pandas Future warning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "imported-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config variables\n",
    "model_name    = config[\"model\"]\n",
    "weights     = config[\"weights\"]\n",
    "include_top   = config[\"include_top\"]\n",
    "train_path    = config[\"train_path\"]\n",
    "features_path   = config[\"features_path\"]\n",
    "labels_path   = config[\"labels_path\"]\n",
    "test_size     = config[\"test_size\"]\n",
    "results     = config[\"results\"]\n",
    "model_path    = config[\"model_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vertical-warrior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded base model and model...\n"
     ]
    }
   ],
   "source": [
    "# Here we are loading the base VGG16 model with weights and then excluding the top dense layer\n",
    "if model_name == \"vgg16\":\n",
    "    base_model = VGG16(weights=weights)\n",
    "    model = Model(base_model.input,base_model.get_layer('fc1').output)\n",
    "    image_size = (224, 224)\n",
    "else:\n",
    "    base_model = None\n",
    "\n",
    "print (\"Successfully loaded base model and model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "limiting-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for layer in base_model.layers:\n",
    "    #print(layer.name)\n",
    "#layer_output = model.get_layer('vgg16').get_layer('block3_conv1').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sonic-colon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '01-whole', '00-damage']\n"
     ]
    }
   ],
   "source": [
    "#path to training dataset\n",
    "#train_labels = os.listdir(train_path)\n",
    "#print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "motivated-static",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.273586  0.        0.       ...  0.        0.        2.312586]]\n",
      "[10.273586  0.        0.       ...  0.        0.        2.312586]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "img = image.load_img('/Users/rishitdholakia/Desktop/Car Damage Detection project/data1a/training/01-whole/0001.jpg', target_size=image_size)\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "feature = model.predict(x)\n",
    "print(feature)\n",
    "flat = feature.flatten()\n",
    "print(flat)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beautiful-leonard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed label - .DS_Store\n",
      "Completed label - 01-whole\n",
      "Completed label - 00-damage\n",
      "Training labels: [1 1 1 ... 0 0 0]\n",
      "Training labels shape: (1840,)\n"
     ]
    }
   ],
   "source": [
    "# path to training dataset\n",
    "train_labels = os.listdir(train_path)\n",
    "\n",
    "# variables to hold features and labels\n",
    "features = []\n",
    "labels   = []\n",
    "\n",
    "# loop over all the labels in the folder\n",
    "for i, label in enumerate(train_labels):\n",
    "    cur_path = train_path + \"/\" + label\n",
    "    for image_path in glob.glob(cur_path + \"/*.jpg\"):\n",
    "        img = image.load_img(image_path, target_size=image_size)\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        feature = model.predict(x) #2D\n",
    "        flat = feature.flatten() # to 1D\n",
    "        features.append(flat)\n",
    "        labels.append(label)\n",
    "    print (\"Completed label - \" + label)\n",
    "\n",
    "# encode the labels using LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le_labels = le.fit_transform(labels)\n",
    "\n",
    "# get the shape of training labels\n",
    "print (\"Training labels: {}\".format(le_labels))\n",
    "print (\"Training labels shape: {}\".format(le_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "indoor-valley",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "enclosed-velvet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "=================================================================\n",
      "Total params: 117,479,232\n",
      "Trainable params: 117,479,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "residential-sugar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and weights to disk..\n",
      "Features and labels saved..\n",
      "End time - 2021-03-20 12:19\n"
     ]
    }
   ],
   "source": [
    "#https://www.christopherlovell.co.uk/blog/2016/04/27/h5py-intro.html\n",
    "#https://machinelearningmastery.com/save-load-keras-deep-learning-models/ -- saving model architecture using JSON and weights using .h5\n",
    "#https://stackoverflow.com/questions/58092765/how-to-save-list-of-extracted-features-in-hdf5-file-python\n",
    "\n",
    "# save features and labels\n",
    "h5f_data = h5py.File(features_path, 'w') # truncate if the file exists\n",
    "h5f_data.create_dataset('dataset_1', data=np.array(features))\n",
    "\n",
    "h5f_label = h5py.File(labels_path, 'w')\n",
    "h5f_label.create_dataset('dataset_1', data=np.array(le_labels))\n",
    "\n",
    "h5f_data.close()\n",
    "h5f_label.close()\n",
    "\n",
    "# save model and weights\n",
    "model_json = model.to_json()\n",
    "with open(model_path + str(test_size) + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save weights\n",
    "model.save_weights(model_path + str(test_size) + \".h5\")\n",
    "print(\"Saved model and weights to disk..\")\n",
    "\n",
    "print (\"Features and labels saved..\")\n",
    "\n",
    "# end time\n",
    "import time\n",
    "end = time.time()\n",
    "print (\"End time - {}\".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-orchestra",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
